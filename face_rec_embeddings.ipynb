{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Activation, AveragePooling2D, BatchNormalization, Concatenate, Conv2D, Dense, Dropout, Flatten\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Input, Lambda, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.applications import Xception\n",
    "\n",
    "from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'custom_face_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of paths to images in the custom_face_data directory\n",
    "\n",
    "imgpaths = []\n",
    "\n",
    "for dirpath, dirname, filenames in os.walk(data_path):\n",
    "    for filename in filenames:\n",
    "        if 'JPG' in filename or 'jpg' in filename or 'jpeg' in filename:\n",
    "            imgpaths.append(os.path.join(dirpath, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgpaths = [i for i in imgpaths if \"DS_Store\" not in i]\n",
    "\n",
    "# Creates pandas dataframe from the imgpaths list for easy data manipulation\n",
    "df = pd.DataFrame(imgpaths, columns = ['ImgPath'])\n",
    "\n",
    "# Gets the identiy of the person from each image path\n",
    "df['Name'] = df.ImgPath.apply(lambda x: x.split('/')[-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 96, 96, 3)]       0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Functional)        (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 21,976,232\n",
      "Trainable params: 1,114,752\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (96, 96, 3)\n",
    "embedding_size = 128\n",
    "\n",
    "# Instantiate Xception Model\n",
    "xception = Xception(weights=\"imagenet\", input_shape=input_shape, include_top=False)\n",
    "xception.trainable = False\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "# Layer for Xception preprocessing\n",
    "layer = Lambda(lambda x: (x/127.5)-1)(inputs)\n",
    "layer = xception(layer)\n",
    "layer = GlobalMaxPooling2D()(layer)\n",
    "layer = Dense(embedding_size*4, activation='relu')(layer)\n",
    "layer = Dense(embedding_size)(layer)\n",
    "layer = Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(layer)\n",
    "model = Model(inputs, layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = r'Triplet Loss/global_max_pooling_FC_4_1_xception.0.4527.hdf5'\n",
    "model.load_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN()\n",
    "def extract_face(imgpath):\n",
    "    '''Function that reads the path to an image into an an image array with cv2, converting the color to RGB.\n",
    "    Uses MTCNN to detect faces in an image and to locate the bounding boxes of the face.\n",
    "    Crops the image to the bounding boxes of the face. \n",
    "    Returns a resized version of the cropped image, with shape (96, 96, 3)\n",
    "    '''\n",
    "    img = cv2.imread(imgpath)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    f = detector.detect_faces(img)\n",
    "    x1, y1, w, h = f[0]['box']\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2 = abs(x1+w)\n",
    "    y2 = abs(y1+h)\n",
    "    face = img[y1:y2, x1:x2]\n",
    "    face = cv2.resize(face, (96,96))\n",
    "    return face\n",
    "\n",
    "def img_to_emb(img_array, embedding_model):\n",
    "    return embedding_model.predict(np.expand_dims(img_array, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the function defined above, get face encodings for every image in database\n",
    "df['Encodings'] = df.ImgPath.apply(lambda x: img_to_emb(extract_face(x), model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to python pickle item for use in live stream face recognition application\n",
    "df.to_pickle('../FacialRecognition/custom_embeddings_xception.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
